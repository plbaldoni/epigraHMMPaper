\documentclass[12pt,oneside]{book}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage[section]{placeins}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage[flushleft]{threeparttable}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{csquotes}
\usepackage{float}
\usepackage{caption}
\usepackage[margin=1in]{geometry}
\usepackage{titling}
\newcommand{\subtitle}[1]{%
\posttitle{%
\par\end{center}
\begin{center}\large#1\end{center}
\vskip0.5em}%
}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\mb}[1]{\mathbf{#1}}
\usepackage{url}
\usepackage[american]{babel}
\usepackage[colorlinks]{hyperref}
\usepackage{appendix}
\AtBeginDocument{%
\hypersetup{
citecolor=black,
linkcolor=black,
urlcolor=blue}
}

\newcommand{\argmax}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{max}}\;}

\captionsetup[table]{name=Web Table}
\captionsetup[figure]{name=Web Figure}

\usepackage{chngcntr}
\counterwithout{figure}{chapter}
\counterwithout{table}{chapter}

\usepackage{setspace}
\doublespacing
\AtBeginDocument{\renewcommand\appendixname{Supporting Information}}

% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{1}

\if1\blind{
\date{%
$^*$Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA\\%
\today
}
\title{{Supporting Information for 'Efficient Detection and Classification of Epigenomic Changes Under Multiple Conditions' by Pedro L. Baldoni$^*$, Naim U. Rashid$^*$, and Joseph G. Ibrahim$^*$}}
} \fi

\if0\blind{
\date{%
\today
}
\title{{Supporting Information for 'Efficient Detection and Classification of Epigenomic Changes Under Multiple Conditions'}}
} \fi
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\maketitle

\appendix
\makeatletter
\renewcommand\thechapter{\Alph{chapter}}
\renewcommand\thesection{\thechapter\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}
\renewcommand{\thetable}{\arabic{table}}
\renewcommand{\thefigure}{\arabic{figure}}
\makeatother

\chapter{}
In this appendix, we present a summary of data accession codes, data pre-processing, and parameter specifications from benchmarked methods.

\section{Data accession codes}

\begin{table}[h!]
\footnotesize
\centering
\caption{GEO sample accession codes of the analyzed data from the ENCODE Consortium}
\begin{tabular}{lccccccc}
\hline
Cell Line & H3K27me3 & H3K36me3 & EZH2 & H3K4me3 & H3K27ac & CTCF & RNA-seq\\
\hline
H1hesc & GSM733748 & GSM733725 & GSM1003524 & GSM733657 & GSM733718 & GSM733672 & GSM758566\\
HelaS3 & GSM733696 & GSM733711 & GSM1003520 & GSM733682 & GSM733684 & GSM733785 & GSM765402\\
Hepg2 & GSM733754 & GSM733685 & GSM1003487 & GSM733737 & GSM733743 & GSM733645 & GSM758575\\
Huvec & GSM733688 & GSM733757 & GSM1003518 & GSM733673 & GSM733691 & GSM733716 & GSM758563\\
\hline
\end{tabular}
\end{table}

\pagebreak
\clearpage

\section{Data Processing}
First, we removed PCR duplicates from the BAM files using SAMTools \cite{li2009sequence} and converted the resulting indexed and sorted files to BED format using BEDTools \cite{quinlan2010bedtools}, as RSEG only accepts such a format as input. Then, the fragment length of each ChIP-seq experiment was estimated using csaw and its functions \textit{correlateReads} and \textit{maximizeCcf}. Finally, using the estimated fragment length, read counts from all cell lines were tabulated for their ChIP replicates using fixed-step and non overlapping windows of size 250bp, 500bp, 750bp, and 1000bp through the R package \textit{bamsignals} \cite{mammana2016package}. For all methods using window-based approaches (csaw, ChIPComp, diffReps, RSEG, THOR, and epigraHMM), we assessed their performance with different window sizes. See Section \ref{s:window} for a discussion about results with different window sizes.

All the methods considered in the data applications and simulation study outputted a set of differential genomic regions/windows that were used for benchmark purposes. THOR output a list of differential peaks in BED6+4 format (\textit{narrowPeak}) with adjusted p-values. RSEG output a WIG file with genomic windows and their posterior probabilities for differential enrichment. diffReps output an annotated TXT file with differential regions of enrichment and their adjusted p-values. DiffBind output a TXT file with differential regions of enrichment and their respective multiple testing corrected FDR. diffReps output a TXT file with differential regions of enrichment and their p-values. csaw output a TSV file with differential regions of enrichment and their FDR adjusted p-values. For a fair FDR thresholding comparison, we control the total FDR and output the differential regions of enrichment based on the set of posterior probabilities as described in the main text. For a comparison between the Viterbi and the FDR thresholding approach, see Section \ref{s:viterbi}.

The following parametrization was used when calling peaks from the benchmarked methods:
\begin{itemize}
\item THOR: \textit{rgt-THOR 'config' --name 'name' -b 'bp' --pvalue 1.0 --output-dir 'output'},
\item RSEG: \textit{rseg-diff -verbose -mode 3 -out 'output' -score 'score' -chrom 'chrom' -bin-size 'bp' -deadzones 'deadzonee' -duplicates 'sample1' 'sample2'},
\item ChIPComp: \textit{ChIPComp(makeCountSet(conf,design,filetype="bam",species="hg19",binsize=bp))},
\item diffReps: \textit{diffReps.pl --gname hg19 --report 'output' --treatment 'sample1' --control 'sample2' --btr 'control1' --bco 'control2' --window 'bp' --pval 1 --nsd 'marktype' --meth 'nb'},
\item DiffBind: \textit{dba.report(dba.analyze(dba.contrast(dba.count(dba(sampleSheet = conf)), categories=DBA\_CONDITION,minMembers=2)),th=1)},
\end{itemize}
such that $\text{bp} = \{250,500,750,100\}$ and $marktype='broad'$ if H3K27me3, H3K36me3, or EZH2, or $marktype='sharp'$ otherwise.

For DiffBind under 3 conditions (Figure 1, main text), the set of differential peaks included all peaks deemed to be differential by DiffBind under an FDR control of 0.05 simultaneously for all three pairwise contrast tests between the cell lines Helas3, Hepg2, and Huvec. In the particular genomic position shown in Figure 1, no differential peaks were reported by DiffBind.

For csaw, we used the following setup:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# List of bam files}
\hlstd{bam.files} \hlkwb{=} \hlkwd{list.files}\hlstd{(}\hlkwc{path}\hlstd{=}\hlkwd{paste0}\hlstd{(tmpdir,}\hlstr{'/chip'}\hlstd{),}\hlkwc{pattern}\hlstd{=}\hlstr{'*.bam$'}\hlstd{,}
                       \hlkwc{full.names}\hlstd{=T)}
\hlstd{bam.files}

\hlcom{# Design matrix}
\hlstd{design} \hlkwb{<-} \hlkwd{model.matrix}\hlstd{(}\hlopt{~}\hlkwd{factor}\hlstd{(cell.type))}
\hlkwd{colnames}\hlstd{(design)} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"intercept"}\hlstd{,} \hlstr{"cell.type"}\hlstd{)}
\hlstd{design}

\hlcom{# Parameters (PCR duplicates already removed and quality score filtered)}
\hlstd{param} \hlkwb{<-} \hlkwd{readParam}\hlstd{(}\hlkwc{dedup} \hlstd{= F)}
\hlstd{param}

\hlcom{# Estimating the average fragment length (rescaling all to 200bp)}
\hlstd{x} \hlkwb{=} \hlkwd{lapply}\hlstd{(bam.files,correlateReads,}\hlkwc{param}\hlstd{=param,}\hlkwc{max.dist}\hlstd{=}\hlnum{250}\hlstd{)}
\hlstd{multi.frag.lens} \hlkwb{=} \hlkwd{list}\hlstd{(}\hlkwd{unlist}\hlstd{(}\hlkwd{lapply}\hlstd{(x,maximizeCcf)),}\hlnum{200}\hlstd{)}
\hlstd{multi.frag.lens}

\hlcom{# Counting reads (for a window size of 250bp, for instance)}
\hlstd{data} \hlkwb{<-} \hlkwd{windowCounts}\hlstd{(bam.files,}\hlkwc{width} \hlstd{=} \hlnum{250}\hlstd{,}\hlkwc{ext} \hlstd{= multi.frag.lens,}
                     \hlkwc{param} \hlstd{= param,}\hlkwc{filter} \hlstd{=} \hlnum{20}\hlstd{)}
\hlstd{data}

\hlcom{# Filtering data}
\hlstd{data.large} \hlkwb{<-} \hlkwd{windowCounts}\hlstd{(bam.files,}\hlkwc{width}\hlstd{=}\hlnum{2500}\hlstd{,}\hlkwc{bin}\hlstd{=T,}\hlkwc{param}\hlstd{=param)}

\hlstd{bin.ab} \hlkwb{<-} \hlkwd{scaledAverage}\hlstd{(data.large,} \hlkwc{scale}\hlstd{=}\hlkwd{median}\hlstd{(}\hlkwd{getWidths}\hlstd{(data.large))}\hlopt{/}
                          \hlkwd{median}\hlstd{(}\hlkwd{getWidths}\hlstd{(data)))}

\hlstd{threshold} \hlkwb{<-} \hlkwd{median}\hlstd{(bin.ab)} \hlopt{+} \hlkwd{log2}\hlstd{(}\hlnum{2}\hlstd{)}

\hlstd{keep.global} \hlkwb{<-} \hlkwd{aveLogCPM}\hlstd{(}\hlkwd{asDGEList}\hlstd{(data))} \hlopt{>}  \hlstd{threshold}

\hlkwd{sum}\hlstd{(keep.global)}

\hlcom{# Creating filtered data}
\hlstd{filtered.data} \hlkwb{<-} \hlstd{data[keep.global,]}

\hlcom{# Testing for DB (assuming composition bias is negligble,}
\hlcom{# i.e. cell lines should exhibit a balanced number of DB regions) }

\hlstd{y} \hlkwb{<-} \hlkwd{DGEList}\hlstd{(}\hlkwd{assay}\hlstd{(filtered.data),} \hlkwc{lib.size} \hlstd{= filtered.data}\hlopt{$}\hlstd{totals)}
\hlstd{y}\hlopt{$}\hlstd{samples}\hlopt{$}\hlstd{norm.factors} \hlkwb{<-} \hlnum{1}
\hlstd{y}\hlopt{$}\hlstd{offset} \hlkwb{<-} \hlkwa{NULL}
\hlstd{y} \hlkwb{<-} \hlkwd{estimateDisp}\hlstd{(y, design)}
\hlstd{fit} \hlkwb{<-} \hlkwd{glmQLFit}\hlstd{(y, design,} \hlkwc{robust} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlstd{out} \hlkwb{<-} \hlkwd{glmQLFTest}\hlstd{(fit,}\hlkwc{contrast} \hlstd{= contrast)}
\hlstd{tabres} \hlkwb{<-} \hlkwd{topTags}\hlstd{(out,} \hlkwd{nrow}\hlstd{(out))}\hlopt{$}\hlstd{table}
\hlstd{tabres} \hlkwb{<-} \hlstd{tabres[}\hlkwd{order}\hlstd{(}\hlkwd{as.integer}\hlstd{(}\hlkwd{rownames}\hlstd{(tabres))),]}

\hlstd{merged} \hlkwb{<-} \hlkwd{mergeWindows}\hlstd{(}\hlkwd{rowRanges}\hlstd{(filtered.data),} \hlkwc{tol}\hlstd{=tol,}
                       \hlkwc{max.width}\hlstd{=max.width)}
\hlstd{tabneg} \hlkwb{<-} \hlkwd{combineTests}\hlstd{(merged}\hlopt{$}\hlstd{id, tabres)}
\end{alltt}
\end{kframe}
\end{knitrout}


For ChIPComp and DiffBind, candidate peaks were called in advance using MACS2 with the following syntax:
\begin{itemize}
\item MACS2: \textit{macs2 callpeak -f BAM -g 2.80e+09 -B 'options' -t 'sample' -c 'control' --outdir 'output' -n 'filename'}
\end{itemize}
such that $options = \{\text{--broad --broad-cutoff 0.1}\}$ if H3K27me3, H3K36me3, or EZH2, or $options = \{\text{-q 0.01}\}$ otherwise.

\section{Software}
epigraHMM was implemented in a R package that is available on the GitHub repository \if1\blind{https://github.com/plbaldoni/epigraHMM}\fi \if0\blind{(BLINDED FOR REVIEW)}\fi.

epigraHMM is a package with a differential peak caller to detect differential enrichment regions from multiple ChIP-seq experiments with replicates. The main function of the package is \textit{epigraHMM}(). The package allows the user to specify a set of parameters that control the Expectation-Maximization (EM) algorithm. These parameters include, for instance, the convergence (and termination) criteria of the algorithm and the threshold value for the rejection controlled EM algorithm. These parameters can be defined by the function \textit{controlEM}(). Please refer to the package documentation (e.g. \textit{?epigraHMM::epigraHMM}) for additional details and the complete help manual.

\section{Code}
The necessary code to replicate the results presented in the main article and in the supplementary material can be downloaded from \if1\blind{https://github.com/plbaldoni/epigraHMMPaper}\fi \if0\blind{(BLINDED FOR REVIEW)}\fi.

\chapter{}
In this appendix, we present additional methodological results and an overview of the EM algorithm proposed in the main article.

\section{Adjustments for nuisance effects}
\label{s:offset}

\subsection{Normalization for non-linear biases via model offsets}
\label{s:loess}

In our analyses, we observed that the magnitude of the local differences in read counts between conditions changed with the average of local read coverage. Here, we accounted for these trended differences to avoid calling spurious differential peaks due to the different magnitude of library sizes across groups. Specifically, we implemented an approach similar to the non-linear normalization method used by csaw as follows \cite{lun2015csaw}. First, we create a reference sample of read counts comprised by the geometric mean of read counts from all replicates and conditions. Then, we fitted a loess curve on the difference between the read counts of each sample and the reference, on the average of those two quantities. A similar approach was first implemented by \cite{lun2015csaw} and is available in their software. Here, we add a continuity correction of 1 to avoid discarding genomic windows with zero counts. Using the smoothed curve as the model offset, we observed better results than a simple correction via either the total sum of read counts or cell-specific median log ratio. The rationale behind this approach is to create a reference library in which each genomic window is the geometric mean of counts across all conditions and replicates, and then read counts are properly adjusted by accounting for the smoothed differences between each individual library and the reference library. A useful way to evaluate the performance of this normalization method is to compare samples with respect to their adjusted read counts. For example, plotting the ratios between counts and the calculated offsets $y_{hij}/\exp(u_{hij})$ for all samples in the study. In Figure \ref{maplot} we show an example of a genomic region from three analyzed cell lines and their respective MA plot, unadjusted ChIP counts, and offset-adjusted ChIP counts. After accounting for the offset, the read counts from Helas3 are adjusted to its larger library size with respect to the other under sequenced cell lines.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics{../../Supp/Figure_Normalization/Figure_Normalization.pdf}}
\end{center}
\caption{MA plot of read counts from three distinct analyzed cell lines (top), unadjusted ChIP read counts (center), and offset-adjusted ChIP read counts (bottom) from a given genomic region on chromosome 19. The blue line in the MA plots shows the offset created via loess smoothing.
\label{maplot}}
\end{figure}

\subsection{Input control adjustment in differential peak calling}

Our implementation (Web Appendix A4) allows the optional inclusion of continuous covariates in the model with state-specific parametrization. The main purpose of the inclusion of such covariates in the model is the adjustment for input control (or any other continuous variable, such as autoregressive counts) that can be helpful in distinguishing background from enrichment signal. Several methods for differential peak calling allow the inclusion of input control in their computational framework \cite{stark2011diffbind,shen2013diffreps,chen2015novel,allhoff2016differential}. However, \cite{lun2015csaw} point out that "(...) controls are mostly irrelevant when testing for DB between ChIP samples.". To evaluate this claim, we ran an analysis of real data and simulated data while accounting for the input control effect.

To asses whether accounting for input control effect leads to an improvement in performance, we utilized the smoothing technique proposed by \cite{chen2015novel} to account for input controls and autoregressive counts. Specifically, we fitted generalized additive models (GAM, instead of loess smoothing) in the data normalization step while accounting for input control (or autoregressive counts) as a covariate. The resulting fitted curve was then used in the analysis as model offsets.

First, we analyzed real data by smoothing the input control effect and autoregressive counts with a two-step approach. Specifically, we first called peaks without the inclusion of extra covariates in the model, and then utilized the called differential peaks from the first step to smooth the covariates for each HMM predicted state. Predicted smoothing curves from the GAM approach were then passed as model offsets in a second step of analysis. As claimed by \cite{lun2015csaw}, we observed minor differences in the results that would justify their inclusion in the analysis. Results from the histone modification mark H3K36me3 are presented in Figure \ref{fig:control2}.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_ENCODE_Control/Figure_PR_H3K36me3_Encode_twocells_500bp.pdf}}
\end{center}
\caption{ROC curves for H3K36me3 utilizing no input controls (epigraHMM), input control only (epigraHMM + Control), autoregressive counts only (epigraHMM + AR Counts), and smoothing of both input controls and autoregressive counts (epigraHMM + Control \& AR Counts)
\label{fig:control2}}
\end{figure}

Next, we reasoned that our approach of modeling input control effect with state-specific parametrization could not be ideal, since independent controls were available for every sample and there could exist sample-specific effects not captured by our model. We then attempted to verify the utility of including input control into the differential binding analysis by simulating data where ChIP-counts were generated such that their log-mean had a linear relationship with input controls (Figure \ref{fig:control3}). We then fitted three different models that differed regarding the inclusion of input control: a model without control, a model with control, and a model with controls where the smoothing was calculated separately for each latent HMM state. Again, results did not show significant improvement by including the effect of control in the analysis.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Sim/Control/Summary/Summary.pdf}}
\end{center}
\caption{Results from simulated data (A) where the log-means of ChIP-seq counts were generated as a linear function of input controls (B). Sensitivity/specificity analyses did not show significant improvement by including the effect of control in the offset scheme.
\label{fig:control3}}
\end{figure}

Overall, we did not observe a significant improvement in performance by including input control in differential peak calling. Although several methods do offer the option of including controls in their analysis pipeline, we did not find that their inclusion was justifiable under our modeling assumptions. Our findings are in agreement with \cite{lun2015csaw}.

\pagebreak
\clearpage

\subsection{GC-content bias in broad marks}

We performed a simulation study to assess the benefits and ability of epigraHMM to adjust for GC-content bias. In this study, we borrowed the method from \cite{teng2017accounting} and used their normalizing denominators to adjust for GC-content bias in our simulations study. As \cite{teng2017accounting} suggest, we utilized their normalizing offsets into our own model to account for the bias results from the simulated GC content. Because the simulated data varied with respect to the sequencing depth, we further included in our model normalizing offsets to adjust for the excess of read enrichment using the loess normalization approach as described in Section \ref{s:loess}.

Data was generated as described in Section 4.1 of our paper, with the addition that GC-content bias was introduced to the mean model. As suggested by \cite{teng2017accounting}, the simulated GC-content effect varied from condition to condition as well as the sequencing depth. In this simulation study, we assessed decreasing, neutral, and increasing effects of GC-content on the mean read count distribution. In Figure \ref{fig:sim_gc_scatter} we show an example of simulated data with increasing GC-content effect on ChIP-seq counts in both conditions. In this example, these conditions varied regarding the depth of sequencing reads.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_Simulation_GC/Summary_Scatter_G113G233.png}}
\end{center}
\caption{Simulation study for GC-content bias correction with epigraHMM. In (A), example of a genomic region from the simulated data. In (B), simulated GC content effect on ChIP-seq counts. Scenario: low depth in condition 1, high depth in condition 2; positive GC effect on ChIP-seq counts in both conditions.
\label{fig:sim_gc_scatter}}
\end{figure}

We assessed the model performance while adjusting for sequencing depth only, GC-content effect only, and simultaneously adjusting for both GC-content and sequencing depth. We observed that the optimal results were achieve only after normalization for both GC and sequencing depth bias. Despite the improvement in performance after the non-linear normalization, we were able to achieve optimal results in terms of true positive rate and false discovery rate of peak calls only after accounting for GC-content bias. These results not only show that our model is able to account for such type of bias, here computed using the methodology from \cite{teng2017accounting}, but also highlight the importance of such an adjustment. These results are shown in Figure \ref{fig:sim_gc_fdr}.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_Simulation_GC/Summary_FDR_G113G233.png}}
\end{center}
\caption{Simulation study for GC-content bias correction with epigraHMM. Average observed true positive rate (y-axis) and observed false discovery rate (x-axis) in 100 simulated data sets for four different GC-content bias correction strategies: naive model without normalization for sequencing depth or GC-content bias, GC-content adjusted model, sequencing depth adjusted model, and GC-content and sequencing depth adjusted model. Optimal results are obtained only when the effect of GC-content is considered together with normalization for depth. The GC-content bias was accounted via model offsets in epigraHMM using the normalizing denominators from \cite{teng2017accounting}.
\label{fig:sim_gc_fdr}}
\end{figure}

To better visualize the results on a per data set basis, Figure \ref{fig:sim_gc_roc} shows the sensitivity and 1-specificity results from all 100 simulated datasets for the aforementioned example. Here, we see that for all data sets only after account for GC-content bias we were able to achieve optimal results.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_Simulation_GC/Summary_ROC_G113G233.png}}
\end{center}
\caption{Simulation study for GC-content bias correction with epigraHMM. Observed sensitivity (y-axis) and observed 1-specificity (x-axis) for each of the 100 simulated data sets four different GC-content bias correction strategies: naive model without normalization for sequencing depth or GC-content bias, GC-content adjusted model, sequencing depth adjusted model, and GC-content and sequencing depth adjusted model. Optimal results are obtained only when the effect of GC-content is considered together with normalization for depth. The GC-content bias was accounted via model offsets in epigraHMM using the normalizing denominators from \cite{teng2017accounting}. Dashed lines connect the observed metrics for each simulated dataset.
\label{fig:sim_gc_roc}}
\end{figure}

\pagebreak
\clearpage

\section{Bayesian Information Criterion (BIC) for Hidden Markov Models}
\label{s:bicsec}

The BIC for hidden Markov models has been discussed by \cite{zucchini2017hidden}. For the presented three-state HMM, one can calculate the BIC as
\begin{align}\label{eq:bic}
BIC &= -2\log\left(\sum_{r=1}^{3}f_{Mr}^{p}\right) + (11+L)\log\left(M\sum_{h=1}^{G}n_{h}\right),
\end{align}
where $f_{Mr}^{p}$ is the forward probability pertaining to the $r^{th}$ state calculated at the (last) $M^{th}$ genomic window (as detailed in the Appendix of the main text), $L$ is the number of mixture components, $G$ is the number of conditions, and $n_{h}$ is the number of replicates pertaining to condition $h$. The number of model parameters to be estimated is $(11+L)$: 6 transition probabilities, 2 initial probabilities, 4 model coefficients pertaining to the emission distributions, and $L-1$ prior probabilities from the mixture model.

As shown in the main text, the proposed HMM is robust to situations where certain combinatorial patterns are rare. However, if pruning rare combinatorial patterns is still of interest, such a task can be performed by making use of the BIC. For the analysis of $G$ experimental conditions with a given BIC threshold $\epsilon$, say $\epsilon=0.01$, and $L=2^G-2$ mixture components, one can prune rare combinatorial patterns by the following algorithm.

\begin{enumerate}
\item Fit the three-state HMM with $L$ mixture components (model $L$) and compute the model BIC, BIC$_{L}$, as in Equation \ref{eq:bic}.
\item Fit a reduced three-state HMM with $L-1$ mixture components (model $L-1$) by excluding the component associated with the rarest combinatorial pattern of enrichment. Compute its BIC, BIC$_{L-1}$.
\item Calculate $\Delta\text{BIC}=(\text{BIC}_{L-1}-\text{BIC}_{L})/\text{BIC}_{L}$. If $|\Delta\text{BIC}|\leq\epsilon$, set $L \leftarrow L-1$ and return to step 1. If $|\Delta\text{BIC}|>\epsilon$, stop and set the model L as the final model.
\end{enumerate}

In scenarios where the number of mixture components is smaller than $2^G-2$, the implemented method initializes the EM algorithm by clustering genomic windows with respect to the posterior probabilities of enrichment obtained from a initial run of a two-state HMM to classify genomic windows into background and enrichment windows. Such an initialization improves the overall computation time by reducing the time to convergence of the presented EM algorithm.

We also compare the results of our method with ChromHMM, an algorithm developed for chromatin segmentation. In Figure \ref{fig:chromHMM}, panels A-D, we present results of ChromHMM with 3 (ideal), 4, 5, and 6 states. By using the BIC for model selection, one could easily choose the number of biologically relevant mixture components to be included in the model, a task that may not be as straightforward in methods such as ChromHMM (see Supplementary Figure 4 in \cite{ernst2012chromhmm}). Our method offers the benefit of simultaneously detecting differential peaks and classifying the combinatorial pattern of enrichment through mixture model posterior probabilities even in the context of genomic segmentation. Despite the choice of the number of mixture components via BIC, epigraHMM appeared to be robust in scenarios with rare combinatorial patterns. This is so because we utilize a constrained parametrization in which only 4 GLM-specific parameters need to be estimated regardless of the number of mixture components, and in the genome-wide analysis of ChIP-seq data one often has enough data to estimate such quantities.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_ChromHMM/Figure_ChromHMM.pdf}}
\end{center}
\caption{Comparative analysis of epigraHMM and ChromHMM with 3 (ideal), 4, 5, 6, 7, and 8 states (panels A-F).
\label{fig:chromHMM}}
\end{figure}

\subsection{Simulation Study}

We assessed the performance of our model selection scheme via BIC with a simulation study. To this end, we re-generated data in the same fashion as described in Section 4 of our paper while removing certain combinatorial patterns. Specifically, to mimic the ENCODE data analyzed in Section 5 of our paper, we generated data for which 3 conditions were available but only 2 out of 6 possible differential combinatorial patterns were available. 

First, it is important to note that for an analysis of 3 conditions, there are $2^3-2 = 6$ possible combinatorial patterns of differential enrichment. In this context, for a mixture model with $L$ components, there are ${6\choose L}$ possible ways to model $L$ components. The choice of the number $L$ of components therefore needs to reflect the relevant biological patterns in the data. In this study, we assessed the algorithm presented in Section \ref{s:bicsec} by fitting all $\sum_{l=1}^{6}{6\choose l}$ possible model and computing their BIC for 100 simulated data sets. On average, the optimal chosen model should be the one with $L=2$ components \textit{and} with the components modeling those relevant ones. In this study, the two relevant patterns simulated were enrichment in condition 1 alone, and co-enrichment of conditions 2 and 3 (similar to Figure 6 of the main paper). As in Section 4 of our paper, we assessed the performance of our model under different SNR levels, different number of replicates per condition, and different genome sizes.

We present our results in Figures \ref{fig:bic_4rep}, \ref{fig:bic_2rep}, and \ref{fig:bic_1rep}. We start our model selection by fitting the full model with 6 components (L=6, rightmost block of the triangle with the highlighted '1'). We then proceed with our algorithm as described in this section and remove 1 combinatorial pattern at a time until the difference in BIC is large enough. As we can see from Figures \ref{fig:bic_4rep}, \ref{fig:bic_2rep}, and \ref{fig:bic_1rep}, this is achieved when L=2 and the combinatorial patterns being modeled is 1 (enrichment condition 1) and 2/3 (co-enrichment of condition 2 and 3). As we can see, our model selection scheme correctly selected the optimal model with the proper number of combinatorial patterns $L$ and the proper patterns themselves.

In accordance with the results presented in Section 4 of our paper, we note that the number of replicates played a major role in the success of our model selections scheme. For example, by comparing Figure \ref{fig:bic_4rep} and Figure \ref{fig:bic_1rep}, we see that more technical/biological replicates lead to models that can be better distinguished in terms of BIC when one is searching for the optimal patterns and number of combinatorial patterns. In summary, the presented model selection scheme allows users to prune combinatorial patterns of interest when one is not interested in modeling certain rare biological patterns from the data.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_BIC/H3K36me3_3G_4R_1e+05W_100SNR_bic.png}}
\end{center}
\caption{Simulation study for model selection via BIC. Simulation scenario: H3K36me3 data, 3 conditions, 4 replicates per condition, $10^5$ genomic windows, observed (estimated from ENCODE) SNR. Dashed lines indicate order of model selection scheme beginning with the full model ('1') and ending with the reduced model ('6'). The optimal model is the one with highlighted '2', since it had a significant lower BIC than any other model with a single differential component. Highlighted number in each block indicated the combinatorial pattern being modeled. For instance '1/2 2 3' indicates a model with three components and the following patterns: co-enrichment of condition 1 and 2, enrichment of condition 2 alone, and enrichment of condition 3 alone. 
\label{fig:bic_4rep}}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_BIC/H3K36me3_3G_2R_1e+05W_100SNR_bic.png}}
\end{center}
\caption{Simulation study for model selection via BIC. Simulation scenario: H3K36me3 data, 3 conditions, 2 replicates per condition, $10^5$ genomic windows, observed (estimated from ENCODE) SNR. Dashed lines indicate order of model selection scheme beginning with the full model ('1') and ending with the reduced model ('6'). The optimal model is the one with highlighted '2', since it had a significant lower BIC than any other model with a single differential component. Highlighted number in each block indicated the combinatorial pattern being modeled. For instance '1/2 2 3' indicates a model with three components and the following patterns: co-enrichment of condition 1 and 2, enrichment of condition 2 alone, and enrichment of condition 3 alone. 
\label{fig:bic_2rep}}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_BIC/H3K36me3_3G_1R_1e+05W_100SNR_bic.png}}
\end{center}
\caption{Simulation study for model selection via BIC. Simulation scenario: H3K36me3 data, 3 conditions, 1 replicate per condition, $10^5$ genomic windows, observed (estimated from ENCODE) SNR. Dashed lines indicate order of model selection scheme beginning with the full model ('1') and ending with the reduced model ('6'). The optimal model is the one with highlighted '2', since it had a significant lower BIC than any other model with a single differential component. Highlighted number in each block indicated the combinatorial pattern being modeled. For instance '1/2 2 3' indicates a model with three components and the following patterns: co-enrichment of condition 1 and 2, enrichment of condition 2 alone, and enrichment of condition 3 alone. 
\label{fig:bic_1rep}}
\end{figure}

\pagebreak
\clearpage

\section{Study on FDR Control and the Viterbi Algorithm}
\label{s:viterbi}

In this section, we present results comparing the FDR controlling approach with the Viterbi algorithm. We evaluated the FDR approach using cutoffs 0.01, 0.05, 0.10, 0.15, and 0.20. We compared the results between the two approaches using window sizes of 250bp, 500bp, 750bp, and 1000bp. Overall, we observed that the Viterbi sequence of states led to similar results than the sequences based on FDR control cutoffs across all choices of window size. Specifically, we observed that the sensitivity and specificity of the sequence of Viterbi states were close to those from FDR control, in particular for FDR control 0.10. These results are shown in Figure \ref{fig:encode.viterbi}. These facts are also reflected by the length and number of called peaks. In Figures \ref{fig:encode.viterbi.h3k36me3} and \ref{fig:encode.viterbi.h3k27me3} we show examples of peak calls of H3K26me3 and H3K27me3, respectively, from all FDR control cutoffs and the Viterbi sequence of states. Overall, we observe minor differences regarding the size of peak calls of the Viterbi and FDR control sequences across different choices of window sizes. These differences were mainly present in the data for H3K27me3, which is known to be a histone mark that expands through broader domains than H3K36me3. Finally, it is worth noting that the Viterbi algorithm gives us a way to call peaks that does not depend on the choice of the FDR cutoff.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_PR_Viterbi/Figure_PR_Viterbi.pdf}}
\end{center}
\caption{FDR-based results from broad marks and Viterbi-based result from epigraHMM with 250bp (A), 500bp (B), 750bp (C), and 1000bp (D).}
\label{fig:encode.viterbi}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_H3K36me3_Viterbi/Figure_H3K36me3_Viterbi.pdf}}
\end{center}
\caption{FDR- and Viterbi-based peak calls from H3K36me3 with 250bp (A), 500bp, (B), 750bp (C), and 1000bp (D).}
\label{fig:encode.viterbi.h3k36me3}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_H3K27me3_Viterbi/Figure_H3K27me3_Viterbi.pdf}}
\end{center}
\caption{FDR- and Viterbi-based peak calls from H3K27me3 with 250bp (A), 500bp, (B), 750bp (C), and 1000bp (D).}
\label{fig:encode.viterbi.h3k27me3}
\end{figure}

\pagebreak
\clearpage

\section{HMM Emission Distributions}

For the consensus background ($r=1$) and consensus enrichment ($r=3$) states, the emission distribution function is
\begin{align}\label{eq:nondiffdensity}
f_{r}(\mb{y}_{..j}|\bs{\psi}_{r}) &= \prod^{G}_{h=1}\prod^{n_{h}}_{i=1}f_{r}(y_{hij}|\bs{\psi}_{r}),\quad r\in\{1,3\}\quad\text{and}\quad y_{hij}\in\{0,1,2,\ldots\},\nonumber\\
&=\prod^{G}_{h=1}\prod^{n_{h}}_{i=1}\text{Pr}(Y_{hij}=y_{hij}|Z_{j}=r;\bs{\psi}_{r}),\nonumber\\
&=\prod^{G}_{h=1}\prod^{n_{h}}_{i=1}\frac{\Gamma(y_{hij}+\phi_{r})}{y_{hij}!\Gamma(\phi_{r})}\left(\frac{\phi_{r}}{\mu_{(r,hij)}+\phi_{r}}\right)^{\phi_{r}}\left(\frac{\mu_{(r,hij)}}{\mu_{(r,hij)}+\phi_{r}}\right)^{y_{hij}}.
\end{align}

For the differential state ($r=2$), the emission distribution is
\begin{align}\label{eq:diffdensity}
f_{2}(\mb{y}_{..j}|\mb{x};\bs{\delta},\bs{\psi}_{2}) &= \sum_{l=1}^{L}\delta_{l}f_{(2,l)}\left(\mb{y}_{..j}|\mb{x}_{l};\bs{\psi}_{(2,l)}\right),\quad y_{hij}\in\{0,1,2,\ldots\},\\
&= \sum_{l=1}^{L}\delta_{l}\prod_{h=1}^{G}\prod_{i=1}^{n_{h}}Pr\left(Y_{hij}=y_{hij}|Z_{j}=2,\mb{x}_{l};\bs{\psi}_{(2,l)}\right),\nonumber\\
&= \sum_{l=1}^{L}\delta_{l}\prod_{h=1}^{G}\prod_{i=1}^{n_{h}}\frac{\Gamma\left(y_{hij}+\phi_{(2,l,h)}\right)}{y_{hij}!\Gamma\left(\phi_{(2,l,h)}\right)}\left(\frac{\phi_{(2,l,h)}}{\mu_{(2,l,hij)}+\phi_{(2,l,h)}}\right)^{\phi_{(2,l,h)}}\times\nonumber\\
&\times\left(\frac{\mu_{(2,l,hij)}}{\mu_{(2,l,hij)}+\phi_{(2,l,h)}}\right)^{y_{hij}}.\nonumber
\end{align}

Apart from the offset $u_{hij}$, we will assume that replicates from the same (different) condition share common (distinct) mean and dispersion parameters under every mixing probability distribution $f_{(2,l)}$. To define all possible combinations of background and enrichment across $G$ conditions, we consider the following sets of singletons $A_{1}$, pairs $A_{2}$, $\ldots$, and $(G-1)$-tuples $A_{G-1}$ such that
\begin{align*}
A_{1} &= \left\{a^{(1)}\left. \right\vert a^{(1)}\in\mathbb{G}_{+}\text{ and }a^{(1)}\leq G\right\},\\
A_{2} &= \left\{(a^{(2)}_{1},a^{(2)}_{2})\left. \right\vert (a^{(2)}_{1},a^{(2)}_{2})\in\mathbb{G}^{2}_{+}\text{ and }a^{(2)}_{1}<a^{(2)}_{2}\leq G\right\},\\
&\vdots\\
A_{G-1} &= \left\{(a^{(G-1)}_{g})^{G-1}_{g=1}\left. \right\vert (a^{(G-1)}_{g})^{G-1}_{g=1}\in\mathbb{G}^{G-1}_{+}\text{ and }a^{(G-1)}_{1}<\ldots<a^{(G-1)}_{G-1}\leq G\right\}.
\end{align*}
The union of all sets $A = \cup^{G-1}_{k=1}A_{k}$ contains an exhaustive list of $L = 2^{G}-2$ elements that determines the differential pattern across $G$ conditions such that each element of $A$ indicates which of the $G$ conditions are enriched. For instance, if $G=3$, $A_{1} = \{1,2,3\}$ and $A_{2} = \{(1,2),(1,3),(2,3)\}$ define the six possible combinations of enrichment and background across three conditions. Then, we define a bijective mapping $A \rightarrow S_{1},\ldots,S_{L}$ and let $x_{hl} = I(h\in S_{l})$ indicate whether the read count of genomic window $j$ from replicate $i$ of condition $h$ is enriched in the mixture component $l$. We model the log-mean $\mu_{(2,l,hij)}$ and log-dispersion $\phi_{(2,l,h)}$ of mixture $l$ from the emission distribution (\ref{eq:diffdensity}) as
\begin{align*}
\log(\mu_{(2,l,hij)}) &= \beta_{1} + \beta_{3}x_{hl} + u_{hij},\quad \text{and}\\
\log(\phi_{(2,l,h)}) &= \lambda_{1} + \lambda_{3}x_{hl}.
\end{align*}
According to this parametrization, $\beta_{1}$ and $\lambda_{1}$ are the baseline log-mean and log-dispersion parameters of the read count distribution from replicates of conditions that are not enriched under the mixing distribution $l$. Conversely, $\beta_{1}+\beta_{3}$ and $\lambda_{1}+\lambda_{3}$ are the baseline log-mean and log-dispersion parameters of the read count distribution from replicates of conditions enriched under the mixing distribution $l$. This choice of parametrization ensures that windows exhibiting differential enrichment across conditions share means and dispersions that are common between the remaining non differential HMM states.

A pseudo code of the presented EM algorithm is below.
\begin{enumerate}
\item{Initialize $\bs{\pi}^{(0)}, \bs{\gamma}^{(0)}, \bs{\delta}^{(0)}, \beta_{1}^{(0)}, \beta_{3}^{(0)}, \lambda_{1}^{(0)}, \lambda_{3}^{(0)}$, such that $\sum_{r=1}^3\pi_{r}^{(0)}=1$ and $\sum_{s=1}^{3}\gamma_{rs}=1$.}
\item{E step ($t\geq1$),}
\begin{enumerate}
\item{Calculate $Pr\left(Z_{j}=r|\mb{y},\mb{x};\bs{\Psi}^{(t-1)}\right)$ and $Pr\left(Z_{j-1}=r,Z_{j}=s|\mb{y},\mb{x};\bs{\Psi}^{(t-1)}\right)$ for all $r$ and $s$ in $\left\{1,2,3\right\}$ and $j=1,\ldots,M$ via Forward-Backward algorithm as detailed in Appendix B of the main article}
\item{Calculate $Pr(W_{jl}=1|Z_{j}=2,\mb{y}_{..j},\mb{x};\bs{\Psi}^{(t-1)})$ for all $l$ $\left\{1,\ldots,L\right\}$ and $j=1,\ldots,M$ as $f_{(2,l)}(\mb{y}_{..j}|\mb{x}_{l};\bs{\psi}_{(2,l)}^{(t-1)})\delta_{l}^{(t-1)}/\sum_{k=1}^{L}f_{(2,k)}(\mb{y}_{..j}|\mb{x}_{k};\bs{\psi}_{(2,k)}^{(t-1)})\delta_{k}^{(t-1)}$}
\end{enumerate}
\item{M step ($t\geq1$),}
\begin{enumerate}
\item Maximize Equation (5) (main text) with respect to the initial and transition probabilities to obtain for all $r$ and $s$ in $\left\{1,2,3\right\}$
\begin{align*}
\pi_{r}^{(t)} &= Pr\left(Z_{1}=r|\mb{y},\mb{x};\bs{\Psi}^{(t-1)}\right)\\
\gamma_{rs}^{(t)} &= \sum_{j=2}^{M}Pr(Z_{j-1}=r,Z_{j}=s|\mb{y},\mb{x};\bs{\Psi}^{(t-1)})/\sum_{j=2}^{M}Pr(Z_{j-1}=r|\mb{y},\mb{x};\bs{\Psi}^{(t-1)})
\end{align*}
\item Maximize Equation (5) with respect to $\bs{\delta}$ to obtain $\bs{\delta}^{(t)}$ such that $\sum_{l=1}^L\delta_{l}^{(t)}=1$.
\item Conditionally upon $\bs{\delta}^{(t)}$, maximize Equation (5) with respect to $\beta_{1}, \beta_{3}, \lambda_{1}, \lambda_{3}$ to obtain $\beta_{1}^{(t)}, \beta_{3}^{(t)}, \lambda_{1}^{(t)}, \lambda_{3}^{(t)}$,
\item Iterate between (b) and (c) until convergence.
\end{enumerate}
\item{Iterate between 2. and 3. until convergence.}
\end{enumerate}

\subsection{$Q$-function of the EM algorithm}
% \label{appendix:appendix_Q}
The $Q$-function of the EM algorithm is defined as $Q\left(\bs{\Psi}|\bs{\Psi}^{(t)}\right) = Q_{0}\left(\bs{\pi},\bs{\gamma}|\bs{\Psi}^{(t)}\right)+Q_{1}\left(\bs{\psi}_{1}|\bs{\Psi}^{(t)}\right)+Q_{2}\left(\bs{\delta},\bs{\psi}_{2}|\bs{\Psi}^{(t)}\right)+Q_{3}\left(\bs{\psi}_{3}|\bs{\Psi}^{(t)}\right)$, such that

\begin{align}
\label{eq:appendix_Q}
Q_{0}\left(\bs{\pi},\bs{\gamma}|\bs{\Psi}^{(t)}\right) &= \sum_{r=1}^{3}\left\{Pr\left(Z_{1}=r|\mb{y},\mb{x};\bs{\Psi}^{(t)}\right)\log(\pi_{r})\right\}+\nonumber\\
&+\sum_{j=2}^{M}\sum_{r=1}^{3}\sum_{s=1}^{3}\left\{Pr\left(Z_{j-1}=r,Z_{j}=s|\mb{y},\mb{x};\bs{\Psi}^{(t)}\right)\log(\gamma_{rs})\right\},\nonumber\\
Q_{1}\left(\bs{\psi}_{1}|\bs{\Psi}^{(t)}\right) &= \sum_{j=1}^{M}Pr\left(Z_{j}=1|\mb{y},\mb{x};\bs{\Psi}^{(t)}\right)\log f_{1}\left(\mb{y}_{..j}|\bs{\psi}_{1}\right),\nonumber\\
Q_{2}\left(\bs{\delta},\bs{\psi}_{2}|\bs{\Psi}^{(t)}\right) &= \sum_{j=1}^{M}Pr\left(Z_{j}=2|\mb{y},\mb{x};\bs{\Psi}^{(t)}\right)\sum_{l=1}^{L}Pr(W_{jl}=1|Z_{j}=2,\mb{y}_{..j},\mb{x};\bs{\Psi}^{(t)})\times\nonumber\\
&\times \log\delta_{l}f_{(2,l)}\left(\mb{y}_{..j}|\mb{x}_l;\bs{\psi}_{(2,l)}\right),\quad\text{and}\nonumber\\
Q_{3}\left(\bs{\psi}_{3}|\bs{\Psi}^{(t)}\right) &= \sum_{j=1}^{M}Pr\left(Z_{j}=3|\mb{y},\mb{x};\bs{\Psi}^{(t)}\right)\log f_{3}\left(\mb{y}_{..j}|\bs{\psi}_{3}\right).
\end{align}

During the $t^{th}$ iteration of the EM-algorithm, one solves $\argmax{\beta_{1}^{(t)}, \beta_{3}^{(t)}, \lambda_{1}^{(t)}, \lambda_{3}^{(t)}} Q_{1}\left(\bs{\psi}_{1}|\bs{\Psi}^{(t)}\right) + Q_{2}\left(\bs{\delta},\bs{\psi}_{2}|\bs{\Psi}^{(t)}\right) + Q_{3}\left(\bs{\psi}_{3}|\bs{\Psi}^{(t)}\right)$ during the maximization step. This problem is analogous to estimating parameters in a weighted NB regression model, since $Q_{1}$, $Q_{2}$, and $Q_{3}$ can be seen as weighted log-likelihood functions from a NB generalized linear model with means and dispersions parametrized as described in the Section 3.1 of the main article.

The forward probabilities are defined as $f_{11}^{p} = \pi_{1}f_{1}(\mb{y}_{..1}|\bs{\psi}_{1})$, $f_{12}^{p} = \pi_{2}f_{2}(\mb{y}_{..1}|\mb{x};\bs{\delta},\bs{\psi}_{2})$, $f_{13}^{p} = \pi_{3}f_{3}(\mb{y}_{..1}|\bs{\psi}_{3})$, and, for $j=1,\ldots,M$, $f_{j1}^{p} = \sum_{l=1}^{3}\gamma_{l1}f_{(j-1)l}^{p}f_{1}(\mb{y}_{..j}|\bs{\psi}_{1})$, $f_{j2}^{p} = \sum_{l=1}^{3}\gamma_{l2}f_{(j-1)l}^{p}f_{2}(\mb{y}_{..j}|\mb{x};\bs{\delta},\bs{\psi}_{2})$, and $f_{j3}^{p} = \sum_{l=1}^{3}\gamma_{l3}f_{(j-1)l}^{p}f_{3}(\mb{y}_{..j}|\bs{\psi}_{3})$. Conversely, the backward probabilities are defined as $b_{Mk}^{p}=1$, $\forall k=1,2,3$, and, for $j=1,\ldots,M$, $b_{j1}^{p} = \sum_{l=1}^{3}\gamma_{1l}b_{(j+1)l}^{p}f_{1}(\mb{y}_{..(j+1)}|\bs{\psi}_{1})$, $b_{j2}^{p} = \sum_{l=1}^{3}\gamma_{2l}b_{(j+1)l}^{p}f_{2}(\mb{y}_{..(j+1)}|\mb{x};\bs{\delta},\bs{\psi}_{2})$, and $b_{j3}^{p} = \sum_{l=1}^{3}\gamma_{3l}b_{(j+1)l}^{p}f_{3}(\mb{y}_{..(j+1)}|\bs{\psi}_{3})$. Then, we have

\begin{align}
\label{eq:appendix_FBalgorithm}
P\left(Z_{j}=k|\mathbf{y},\mathbf{x};\bs{\Psi}\right) &= \frac{f_{jk}^{p}b_{jk}^{p}}{\sum_{l=1}^{3}f_{Ml}^{p}},\qquad \forall j=1,\ldots,M\quad\text{and}\quad k=1,2,3,\nonumber\\
P\left(Z_{j-1}=l,Z_{j}=1|\mathbf{y},\mathbf{x};\bs{\Psi}\right) &= \frac{f_{(j-1)l}^{p}\gamma_{l1}f_{1}(\mb{y}_{..j}|\bs{\psi}_{1})b_{j1}^{p}}{\sum_{l=1}^{3}f_{Ml}^{p}},\nonumber\\
P\left(Z_{j-1}=l,Z_{j}=2|\mathbf{y},\mathbf{x};\bs{\Psi}\right) &= \frac{f_{(j-1)l}^{p}\gamma_{l2}f_{2}(\mb{y}_{..j}|\mb{x};\bs{\delta},\bs{\psi}_{2})b_{j2}^{p}}{\sum_{l=1}^{3}f_{Ml}^{p}},\nonumber\\
P\left(Z_{j-1}=l,Z_{j}=3|\mathbf{y},\mathbf{x};\bs{\Psi}\right) &= \frac{f_{(j-1)l}^{p}\gamma_{l3}f_{3}(\mb{y}_{..j}|\bs{\psi}_{3})b_{j3}^{p}}{\sum_{l=1}^{3}f_{Ml}^{p}},\forall j=2,\ldots,M\text{ and }l=1,2,3.
\end{align}

\chapter{}
In this appendix, we present an overview of the simulation scenarios and additional results.

\section{Read Count Simulation}
\label{s:sim1}

In this section, we present additional results from the read count based simulation. 

For each scenario, we simulated a hundred data sets as follows. First, we generated a sequence of hidden states with length $M$ from a first-order Markov chain with $2^G$ states representing every combination of background and enrichment across $G$ conditions. Here, we let states 1 and $2^G$ represent consensus background and consensus enrichment, respectively. Transition probabilities were chosen such that long sequences of enrichment regions (average length of 50 genomic windows) and equal proportions of differential states were generated, while the majority of the simulated states pertained to consensus background. Secondly, read counts were simulated for $n$ replicates from $G$ conditions following NB distributions with mean and dispersion parameters that led to a given SNR and respected the differential pattern of enrichment determined by the hidden state. For each scenario, this setup led to a simulated matrix of counts of dimension $M\times(n\times G)$. The aim of this study was to assess whether the presented model was able to aggregate all $2^G-2$ simulated differential hidden states into its differential HMM state while maintaining a precise parameter estimation scheme. The model parameters used in this simulated study were estimated from ENCODE data pertaining to H3K36me3 and H3K27me3 histone modification marks and a shown in the tables presented in this section.

Overall, while results were similar regarding different number of genome sizes and histone modification marks, the number of replicates played a major role in the performance of the model. In scenarios with either low SNR or high number of conditions, more replicates were needed to achieve better model performance. However, under the observed SNR, two replicates were sufficient to achieve a small relative bias regarding the estimation of most of the model parameters throughout all the evaluated scenarios. This is in agreement with the ENCODE Consortium guidelines, which recommends two technical or biological replicates to achieve best performance in ChIP-seq experiments.

\begin{center}
\input{../../Supp/Table_Simulation_ReadCounts/Table_Simulation_ReadCounts_H3K27me3_1e+06.tex}
\end{center}

\begin{center}
\input{../../Supp/Table_Simulation_ReadCounts/Table_Simulation_ReadCounts_H3K36me3_1e+06.tex}
\end{center}

Next, we assessed the sensitivity of our method to detect simulated differential regions of enrichment. First, differential regions were defined from the  HMM posterior probabilities pertaining to the differential state by controlling the total FDR as defined in Section 3.2 (main text). For different nominal FDR threshold levels, the model sensitivity was estimated as the proportion of windows correctly assigned as differential out of the total number of simulated differential windows. Additionally, the observed FDR was calculated as the proportion of genomic windows incorrectly called as differential out of the total number of called differential windows. In Figures~\ref{fig:sim1.fig1}-\ref{fig:sim1.fig3}, panel A shows the average observed true positive rate (y-axis) and the observed FDR (x-axis) for different nominal FDR levels across a hundred simulated data. Results are shown for different levels of SNR, number of conditions, and number of replicates per condition. Overall, we observed that the number of replicates per condition played a major role on the sensitivity levels of the model, in which scenarios with two and four replicates had the best results regardless of the number of conditions and SNR levels. For scenarios with either high number of conditions or low SNR levels, more replicates were needed to achieve higher sensitivity.

Finally, we used the estimated mixture model posterior probabilities $Pr(W_{jl}=1|Z_{j}=2,\mb{y}_{..j},\mb{x};\hat{\bs{\Psi}})$, $j=1,\ldots,M$, to classify the differential combinatorial patterns of enrichment of detected differential windows. To this end, we first calculated the maximum estimated mixture model posterior probability across all $L$ components to determine the most likely differential combinatorial pattern from genomic windows assigned to be part of the differential state. Then, we compared the window-based classification with the true window-based simulated states from the Markov Chain (states $2,\ldots,G-1$). In Figures~\ref{fig:sim1.fig1}-\ref{fig:sim1.fig3}, panel B shows the confusion matrices of classified (x-axis) and simulated (y-axis) differential windows for a scenario with three conditions. Differential combinatorial patterns of enrichment are represented by the sequences of letters 'E' (enrichment) and 'B' (background), such that each letter corresponds to the status of a given condition. The number of windows (averaged over a all simulated data sets) is shown as entries of the matrices and represented by the color scale. Darker colors on the diagonal entries indicate better agreement between simulated and classified patterns. By utilizing the posterior probabilities from the mixture model, we observed a good performance when classifying the differential combinatorial pattern of enrichment from differential windows. Results were best under scenarios with higher number of replicates or SNR.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.7]{../../Supp/Figure_ROC_ReadCounts/Figure_ROC_ReadCounts_H3K27me3_1e+06.pdf}}
\end{center}
\caption{Read count simulation. (A): average observed TPR and FDR for different nominal FDR threshold levels for various scenarios in simulated data of H3K27me3 with $10^6$ genomic windows. (B): confusion matrices are shown for the 3 conditions scenario. On x- and y-axes the labels indicate the differential classified and simulated patterns, respectively. For instance, EBE denotes enrichment in conditions 1 and 3 only. Darker colors on the diagonal of the matrix indicate better agreement.}
\label{fig:sim1.fig1}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.7]{../../Supp/Figure_ROC_ReadCounts/Figure_ROC_ReadCounts_H3K36me3_1e+06.pdf}}
\end{center}
\caption{Read count simulation. (A): average observed TPR and FDR for different nominal FDR threshold levels for various scenarios in simulated data of H3K36me3 with $10^5$ genomic windows. (B): confusion matrices are shown for the 3 conditions scenario. On x- and y-axes the labels indicate the differential classified and simulated patterns, respectively. For instance, EBE denotes enrichment in conditions 1 and 3 only. Darker colors on the diagonal of the matrix indicate better agreement.}
\label{fig:sim1.fig2}
\end{figure}

\pagebreak
\clearpage

\section{Sequencing Read Simulation}
\label{s:sim2}
In this section, we present additional results from the sequencing read simulation using different FDR control threshold for differential peak call.

We performed a second simulation study aiming to compare the proposed model with the current DPCs ChIPComp, csaw, DiffBind, diffReps, RSEG, and THOR, since none of them was designed to accept matrices of window-based read counts as input. To this purpose, we revisited the simulation study presented by \cite{lun2015csaw} where data were generated in a more general scheme without a particular read count model assumption. Here, sequencing reads from ChIP-seq experiments were generated for two conditions and two replicates per condition. For the differential peaks callers ChIPComp and DiffBind that require sets of candidate regions, we followed the analyses presented by \cite{lun2015csaw} and called peaks in advance using HOMER. Those were then used as input in the respective software for differential call. For ChIPComp and DiffBind, we attempted to call peaks in advance using MACS2. However, MACS2. exhibited issues to work on simulated data as it was not able to detect peaks. Here, we adapted their simulation pipeline aiming to generate broad and diffuse differential regions of enrichment. Specifically, a total of 4000 binding sites spaced 60-65 kbp apart were simulated such that each site was formed by three neighboring peaks 10kb wide. For each peak, the number of sequencing reads were simulated from a NB distribution with mean 300 and dispersions sampled from an inverse chi-squared distribution with 20 degrees of freedom. Reads were positioned on peak sites to form smooth binding profiles. To introduce differential enrichment, one or two peaks from 1000 binding sites were randomly chosen and reads pertaining to them were removed from the sequencing library in one of the two conditions. This process was repeated for the second condition, which led to a total of 2000 differential peaks. Background reads were added to the library to maintain the realistic aspects of the experiment. A hundred simulated data sets were generated and peaks were called by all the methods under multiple nominal FDR thresholds. For our method and RSEG, window-based posterior probabilities were used to control the total FDR. For illustration purposes, we refer to the method presented in this article as epigraHMM.

Specifically, panel D from Figures \ref{fig:sim2.fig1}, \ref{fig:sim2.fig2}, \ref{fig:sim2.fig3}, and \ref{fig:sim2.fig4} show example of peak calls using FDR control cutoffs 0.01, 0.10, 0.15, and 0.20, respectively. Overall, results were consistent across different choices of FDR control. This fact is also shown by the observed sensitivity and false discovery rate from all methods (panels A). We observed a clear distinction of methods regarding the observed sensitivity and specificity such that RSEG, diffReps, and THOR exhibited the highest observed FDR and ChIPComp and DiffBind exhibited the lowest sensitivity.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.7]{../../Supp/Figure_Overview_SequencingReads/Figure_Simulation_SequencingReads_1.pdf}}
\end{center}
\caption{Sequencing read simulation. (A): average observed sensitivity and FDR for various methods under different nominal FDR levels. (B): scatter plot of average ratio of called and simulated peaks (y-axis) and average number of called peaks intersecting true differential regions (x-axis) for different nominal FDR levels. (C): box plot of computing time (in minutes) for various algorithms. (D): an example of differential peak calls under a nominal FDR threshold 0.01. Shaded areas indicate true differential peaks.}
\label{fig:sim2.fig1}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.7]{../../Supp/Figure_Overview_SequencingReads/Figure_Simulation_SequencingReads_10.pdf}}
\end{center}
\caption{Sequencing read simulation. (A): average observed sensitivity and FDR for various methods under different nominal FDR levels. (B): scatter plot of average ratio of called and simulated peaks (y-axis) and average number of called peaks intersecting true differential regions (x-axis) for different nominal FDR levels. (C): box plot of computing time (in minutes) for various algorithms. (D): an example of differential peak calls under a nominal FDR threshold 0.10. Shaded areas indicate true differential peaks.}
\label{fig:sim2.fig2}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.7]{../../Supp/Figure_Overview_SequencingReads/Figure_Simulation_SequencingReads_15.pdf}}
\end{center}
\caption{Sequencing read simulation. (A): average observed sensitivity and FDR for various methods under different nominal FDR levels. (B): scatter plot of average ratio of called and simulated peaks (y-axis) and average number of called peaks intersecting true differential regions (x-axis) for different nominal FDR levels. (C): box plot of computing time (in minutes) for various algorithms. (D): an example of differential peak calls under a nominal FDR threshold 0.15. Shaded areas indicate true differential peaks.}
\label{fig:sim2.fig3}
\end{figure}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale = 0.7]{../../Supp/Figure_Overview_SequencingReads/Figure_Simulation_SequencingReads_20.pdf}}
\end{center}
\caption{Sequencing read simulation. (A): average observed sensitivity and FDR for various methods under different nominal FDR levels. (B): scatter plot of average ratio of called and simulated peaks (y-axis) and average number of called peaks intersecting true differential regions (x-axis) for different nominal FDR levels. (C): box plot of computing time (in minutes) for various algorithms. (D): an example of differential peak calls under a nominal FDR threshold 0.20. Shaded areas indicate true differential peaks.}
\label{fig:sim2.fig4}
\end{figure}

\begin{figure}
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_Overview_SequencingReads/Figure_SequencingReads_Example.pdf}}
\end{center}
\caption{Sequencing read simulation. Examples of differential called peaks from the various methods under an FDR control of 0.05.}
\label{fig:sim2.fig5}
\end{figure}

\chapter{}
In this appendix, we present an overview of the application on data from the ENCODE Consortium.

\section{RNA-seq data and gene transcription}
\label{s:rnaseq}
Under the three cell lines scenario (presented in the main text), we used RNA-seq experimental data from the ENCODE Consortium on Helas3, Hepg2, and Huvec human cells to quantify the expression levels of genes as follows. First, we used Salmon \cite{patro2017salmon} to quantify transcript expression from cell-specific RNA-seq experiments. We then calculated, using the R package $tximport$ \cite{soneson2015differential}, estimated counts using abundance estimates (transcripts per million, TPM) scaled up to the average transcript length over samples and library size. This step ensures that counts computed from Salmon are not correlated with the average transcript length. Secondly, we calculated the number of ChIP-seq reads from H3K4me3 and H3K27ac overlapping gene promoters. Promoter regions extend around the transcription start site 2000 base pairs upstream and 200 base pair downstream. Finally, read counts from RNA-seq and ChIP-seq were normalized for sequencing depth using DESeq2.

For the two cell line scenario, differentially transcribed genes were defined through log2 fold changes of H3K36me3 ChIP-seq read counts. We observed several cases in which differentially expressed genes (defined by RNA-seq data) did not exhibit differential enrichment for H3K36me3. However, due to the activating roles of H3K36me3 on gene transcription, we follow the ideas presented by \cite{steinhauser2016comprehensive} and \cite{ji2013differential} and defined differentially transcribed genes based on log2 fold changes of H3K36me3 ChIP-seq read counts.

Sensitivity and specificity metrics were calculated on the window-level as follows. For non-overlapping genomic windows $b_{1},\ldots,b_{M}$, let $g_{j}=I(b_{j}\in\text{ differentially transcribed gene})$ and $d_{j}=I(b_{j}\in\text{ differential peak})$ denote the indicators of genomic windows being associated with either differential gene bodies or differential peaks, respectively, for $j=1,\ldots,M$, for a given method and nominal FDR level. Then, the observed sensitivity (TPR), specificity (1-FPR), and FDR were calculated as follows:
\begin{align}
\text{Sensitivity} &= \frac{\sum_{j=1}^{M}{g_{j}d_{j}}}{\sum_{j=1}^{M}{g_{j}}}\nonumber\\
\text{Specificity} &= \frac{\sum_{j=1}^{M}{(1-g_{j})(1-d_{j})}}{\sum_{j=1}^{M}{(1-g_{j})}}\nonumber\\
\text{FDR} &= \frac{\sum_{j=1}^{M}{(1-g_{j})d_{j}}}{\sum_{j=1}^{M}{d_{j}}}\nonumber
\end{align}

We present additional results using log2 FC 1, 1.5, 2.5, and 3 in Figure~\ref{fig:LFC}. Overall the presented model outperformed all current methods regardless of the choice of FC cutoff, as we maintained the highest sensitivity for a limited observed false discovery rate. RSEG showed significant higher observed false discovery rate in all the scenarios.

\begin{figure}
\begin{center}
\centerline{\includegraphics[scale = 0.75]{../../Supp/Figure_PR_LFC/Figure_PR_LFC.pdf}}
\end{center}
\caption{ROC curves for H3K36me3 differential peaks covering differentially transcribed gene bodies defined if having absolute $LFC>1$ (A), $LFC>1.5$ (B), $LFC>2.5$ (C), or $LFC>3$ (D).}
\label{fig:LFC}
\end{figure}

\section{Study on Window Sizes}
\label{s:window}

We compared methods regarding the metrics used in this paper to analyze broad marks using window sizes of 250bp, 500bp , 750bp, and 1000bp. Overall, results were consistent across different window sizes. The HMM-based methods RSEG and THOR appeared to be highly sensitive to the window size and showed better results for 1000bp. However, the presented model appeared to be robust to all scenarios as it consistently called a small number of broad peaks overall (Figures \ref{fig:encode.broad.250}, \ref{fig:encode.broad.750}, and \ref{fig:encode.broad.1000}, panels C). The methods csaw, ChIPComp, diffReps, and DiffBind exhibited fragmented and narrow differential peaks regardless of the window size. The performance of all methods appeared to be consistent to the choice of window size under sharp data set. The presented model was robust in all the scenarios as it was able to detect large differences between read counts of the analyzed cell lines.


\begin{figure}
\begin{center}
\centerline{\includegraphics[scale = 0.65]{../../Supp/Figure_Broad_250bp/Figure_Broad.pdf}}
\end{center}
\caption{Results from broad marks (250bp). (A): ROC curves of differentially transcribed gene coverage based on H3K36me3 differential peak calls. (C): average number (y-axis) and size (x-axis) of H3K27me3 called peaks for various methods and different nominal FDR thresholds. (B), (D), and (F): example of peak calls from H3K36me3, H3K27me3, and EZH2, respectively. (E): computing time of genome-wide analysis of broad marks from various methods.}
\label{fig:encode.broad.250}
\end{figure}

\begin{figure}
\begin{center}
\centerline{\includegraphics[scale = 0.65]{../../Supp/Figure_Broad_750bp/Figure_Broad.pdf}}
\end{center}
\caption{Results from broad marks (750bp). (A): ROC curves of differentially transcribed gene coverage based on H3K36me3 differential peak calls. (C): average number (y-axis) and size (x-axis) of H3K27me3 called peaks for various methods and different nominal FDR thresholds. (B), (D), and (F): example of peak calls from H3K36me3, H3K27me3, and EZH2, respectively. (E): computing time of genome-wide analysis of broad marks from various methods.}
\label{fig:encode.broad.750}
\end{figure}

\begin{figure}
\begin{center}
\centerline{\includegraphics[scale = 0.65]{../../Supp/Figure_Broad_1000bp/Figure_Broad.pdf}}
\end{center}
\caption{Results from broad marks (1000bp). (A): ROC curves of differentially transcribed gene coverage based on H3K36me3 differential peak calls. (C): average number (y-axis) and size (x-axis) of H3K27me3 called peaks for various methods and different nominal FDR thresholds. (B), (D), and (F): example of peak calls from H3K36me3, H3K27me3, and EZH2, respectively. (E): computing time of genome-wide analysis of broad marks from various methods.}
\label{fig:encode.broad.1000}
\end{figure}

\begin{figure}
\centerline{\includegraphics[scale = 0.65]{../../Supp/Figure_Narrow_500bp/Figure_Narrow.pdf}}
\caption{Results from sharp marks (500bp). (A) and (C): median $\log_{2}FC$ and correlation between cell lines of ChIP-seq counts from differential called peaks (FDR 0.05, sorted by the absolute LFC) for CTCF and H3K4me3, respectively. (B), (D), and (F): example of broad peak calls from CTCF, H3K4me3, and H3K27ac, respectively. (E): computing time of genome-wide analysis of sharp marks from various methods.}
\label{fig:encode.sharp.500}
\end{figure}

\begin{figure}
\centerline{\includegraphics[scale = 0.65]{../../Supp/Figure_Narrow_750bp/Figure_Narrow.pdf}}
\caption{Results from sharp marks (750bp). (A) and (C): median $\log_{2}FC$ and correlation between cell lines of ChIP-seq counts from differential called peaks (FDR 0.05, sorted by the absolute LFC) for CTCF and H3K4me3, respectively. (B), (D), and (F): example of broad peak calls from CTCF, H3K4me3, and H3K27ac, respectively. (E): computing time of genome-wide analysis of sharp marks from various methods.}
\label{fig:encode.sharp.750}
\end{figure}

\begin{figure}
\centerline{\includegraphics[scale = 0.65]{../../Supp/Figure_Narrow_1000bp/Figure_Narrow.pdf}}
\caption{Results from sharp marks (1000bp). (A) and (C): median $\log_{2}FC$ and correlation between cell lines of ChIP-seq counts from differential called peaks (FDR 0.05, sorted by the absolute LFC) for CTCF and H3K4me3, respectively. (B), (D), and (F): example of broad peak calls from CTCF, H3K4me3, and H3K27ac, respectively. (E): computing time of genome-wide analysis of sharp marks from various methods.}
\label{fig:encode.sharp.1000}
\end{figure}

\section{Classification of Combinatorial Patterns of Protein-DNA Binding Activity and Their Associations With Gene Expression}
\label{s:patterns}

Lastly, we jointly analyzed data from cell lines Helas3, Hepg2, and Huvec to assess the performance and biological relevance of the classification of differential combinatorial patterns of enrichment from H3K4me3 and H3K27ac. These epigenomic marks have been associated with gene transcription and are often deposited on promoter regions of actively transcribed gene bodies. First, we evaluated the classification performance of differential combinatorial patterns of enrichment across cell lines by making use of the estimated mixture model posterior probabilities. Given the differential HMM state, these posterior probabilities allow us assess whether read counts from genomic windows are likely to be generated from a particular combinatorial pattern of enrichment. Secondly, we compared the biological role of the classified patterns with gene expression data. To this end, RNA-seq and ChIP-seq read counts were mapped onto gene bodies and gene promoters, respectively. For the former, we used counts from abundance estimates scaled using the average transcript length over samples \cite{soneson2015differential}. Using DESeq2 \cite{love2014moderated}, normalization between samples was performed to avoid spurious differences due to sequencing depth in both RNA-seq and ChIP-seq data. Then, pairwise LFC of read counts between cell lines were calculated. Genes with zero counts or with low total read count across cell lines were excluded from the analysis (25\% of the protein-coding genes). Finally, we used the maximum window-based posterior probability of the presented mixture model to classify the combinatorial patterns of enrichment from the resulting genes whose promoters overlapped differential peaks.

Figure~\ref{fig:fig_tern} shows the main results from our analyses under a nominal FDR control of 0.05. At the top, we present ternary density plots of differential \textit{peaks} and their associated ChIP-seq read counts. The colors indicate the classified differential pattern of enrichment of peaks based on window-based posterior probabilities of the mixture model. We observed that the classification pattern agreed with the observed direction of enrichment from ChIP-seq data (vertices and opposite sides of the triangle vertices). At the bottom, we show the scatter plots of LFCs between cell lines of \textit{gene} bodies (RNA-seq counts) and \textit{gene} promoters (ChIP-seq counts), along with their Pearson correlation, for some of the classified combinatorial patterns of enrichment. As expected from the activating roles of H3K27ac and H3K4me3, we observed a high agreement between ChIP-seq and RNA-seq LFCs. Here, the colors indicate the classified differential pattern of activation of genes overlapping differential called peaks. These results show that the classified pattern of epigenomic change across the three cell lines agreed with the observed direction of gene expression and highlight the novelties of the presented model. We were able to accurately classify the differential pattern of enrichment of both called peaks (ternary plots) and genes overlapping called peaks (scatter plots) under more than two conditions. The embedded mixture model and its posterior probabilities generalizes the problem of differential peak calling for multiple conditions and provide a tool that is not yet available in any other method presented in the literature.

\begin{figure}
\centerline{\includegraphics[scale = 0.65]{../../Supp/Figure_Ternary/Figure_Ternary.pdf}}
\caption{Ternary plots (top) of ChIP-seq counts mapped on differential peaks and scatter plots (bottom) of $\log_{2}FC$s (LFC) between cell lines of ChIP-seq (x-axis) and RNA-seq counts (y-axis) mapped on genes intersecting differential peaks. Colors indicate the classified combinatorial pattern of peak enrichment (ternary plots) and gene activation (scatter plots). Correlations indicate high agreement between ChIP-seq and RNA-seq $\log_{2}FC$s for these activating marks.
\label{fig:fig_tern}}
\end{figure}


\section{Genomic Segmentation Analysis of H3K36me3 and CTCF}
\label{s:segment}
\begin{figure}
\centerline{\includegraphics{../../Supp/Figure_MultiMarks/Figure_MultiMarks.pdf}}
\caption{Genomic segmentation analysis of H3K36me3 and CTCF in Helas3 cell line. The chosen model parametrization and the normalization for non-linear biases via model offsets allow the segmentation of highly diverse epigenomic marks. The implemented hidden Markov model is able to properly account for the differences in length of enrichment regions between CTCF (short) and H3K36me3 (broad).
\label{fig:fig_tern}}
\end{figure}

\bibliographystyle{amsplain}
\bibliography{bibliography}

\end{document}
